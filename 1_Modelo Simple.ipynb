{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "e6ccca9e-4fec-44af-a8b7-d034101cb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "99449de6-85e8-41e9-b4ea-7e50866d1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "f3eea338-d373-4d32-8815-54ba0a156e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/ConstanzaBaiardi/Documents/CursoITBA/skin-dataset-classification/mlruns/1', creation_time=1766094357481, experiment_id='1', last_update_time=1766094357481, lifecycle_stage='active', name='MLP_Clasificador_Imagenes', tags={}>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"MLP_Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "d21eeefb-bc83-4931-acbc-65ca26d10cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "573d2f49-abfd-444a-a947-712c1737eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para loguear una figura matplotlib en TensorBoard\n",
    "def plot_to_tensorboard(fig, writer, tag, step): #agarra una figura de matplotlib y la pasa a tensorflow\n",
    "    buf = io.BytesIO() #archivo temporal en memoria\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf).convert(\"RGB\")\n",
    "    image = np.array(image)\n",
    "    image = torch.tensor(image).permute(2, 0, 1) / 255.0\n",
    "    writer.add_image(tag, image, global_step=step) #en tensorboard vamos a loggear toda la dinamica del entrenamiento y despues lo exportamos a mlflow\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "4901b00e-6c31-4af2-ab6d-1cc383687d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para matriz de confusión y clasificación\n",
    "def log_classification_report(model, loader, writer, step, prefix=\"val\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.label_encoder.classes_)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    ax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "    # Guardar localmente y subir a MLflow\n",
    "    fig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "    fig_cm.savefig(fig_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    os.remove(fig_path)\n",
    "\n",
    "    plot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=train_dataset.label_encoder.classes_)\n",
    "    writer.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "    # También loguear texto del reporte\n",
    "    with open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    mlflow.log_artifact(f.name)\n",
    "    os.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "2d6564e0-f970-461a-8ab4-5d19e0d55040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de logs\n",
    "log_dir = \"runs/mlp_experimento_1\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "41919c3b-76d8-4eb0-810a-62ce743752de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        class_names = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "        for cls in class_names:\n",
    "            cls_dir = os.path.join(root_dir, cls) #recprrp todos los archivos del directorio y todos los que terminen en png,jpg y jpeg los agarro\n",
    "            for fname in os.listdir(cls_dir):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.image_paths.append(os.path.join(cls_dir, fname))\n",
    "                    self.labels.append(cls)\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx): #nunca entro con la imagen original\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        label = self.labels[idx] #devuelvo la imagen y la etiqueta numerica entre 0 y 8\n",
    "\n",
    "        if self.transform: #si se tanforma la imagen por algun motivo, dame la imagen aumentada\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "1bc0d2e4-319e-4f95-a59b-565182681864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#usamos la librerira albumentations para hacer aumentacion de datos, tambien aumenta las anotaciones cuando corresponda\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(64, 64), #super necesario para que todas las imagenes tengan el mismo tamaño\n",
    "    \n",
    "     #MODIFICACIONES PUNTO 4\n",
    "      \n",
    "    A.HorizontalFlip(p=0.5), #la mitad de las veces le doy vuelta horizontalmente la imagen\n",
    "    A.RandomBrightnessContrast(p=0.2), #la mitad de las veces le cambio el brillo y el contraste\n",
    "    A.ShiftScaleRotate(\n",
    "       shift_limit=0.05,\n",
    "       scale_limit=0.1,\n",
    "       rotate_limit=15,\n",
    "       p=0.5\n",
    "    ),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2() #para entrar al modelo tiene que estar en formato tensor\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "32743888-c68f-4a1a-a5e0-afe766b91486",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_transform = A.Compose([ \n",
    "    A.Resize(64, 64),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "a707a13e-87cc-4c2b-89fd-b83ff1fd9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"data/Split_smol/train\"\n",
    "val_dir = \"data/Split_smol/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "5e18375e-9fb1-4084-8338-302ca99f8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "9a9d4d33-e68d-4ccb-8b0e-f18deabc659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size=64*64*3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047af22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "585580ed-3db0-4687-8ab5-a09abacc621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "model = MLPClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f4415ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.1.weight 4.776884452439845e-07 0.005208674818277359\n",
      "model.3.weight -1.6282203432638198e-05 0.02549908496439457\n",
      "model.5.weight -0.0004465052334126085 0.04967690631747246\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        print(name, param.mean().item(), param.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "da9b8088-283f-4549-8c86-2fec28283e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validación\n",
    "def evaluate(model, loader, epoch=None, prefix=\"val\"):\n",
    "    log_classification_report(model, val_loader, writer, step=epoch, prefix=\"val\")\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Loguear imágenes del primer batch\n",
    "            if i == 0 and epoch is not None:\n",
    "                img_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "                writer.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    avg_loss = loss_sum / len(loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "        writer.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "a08d5e76-139b-43b0-a5f0-a781b0a22463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 22/22 [00:08<00:00,  2.74it/s]\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 2.4737, Accuracy: 27.69%\n",
      "  Val   Loss: 1.7539, Accuracy: 40.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 22/22 [00:06<00:00,  3.32it/s]\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  Train Loss: 1.7944, Accuracy: 40.32%\n",
      "  Val   Loss: 1.7649, Accuracy: 34.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 22/22 [00:06<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  Train Loss: 1.4976, Accuracy: 45.05%\n",
      "  Val   Loss: 1.3436, Accuracy: 47.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 22/22 [00:06<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  Train Loss: 1.3081, Accuracy: 50.65%\n",
      "  Val   Loss: 1.3780, Accuracy: 51.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 22/22 [00:06<00:00,  3.24it/s]\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  Train Loss: 1.3814, Accuracy: 46.48%\n",
      "  Val   Loss: 1.2583, Accuracy: 48.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 22/22 [00:06<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  Train Loss: 1.2470, Accuracy: 51.22%\n",
      "  Val   Loss: 1.1655, Accuracy: 59.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 22/22 [00:06<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  Train Loss: 1.2202, Accuracy: 53.23%\n",
      "  Val   Loss: 1.1400, Accuracy: 54.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 22/22 [00:06<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  Train Loss: 1.1943, Accuracy: 52.22%\n",
      "  Val   Loss: 1.1159, Accuracy: 54.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 22/22 [00:06<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  Train Loss: 1.1780, Accuracy: 55.81%\n",
      "  Val   Loss: 1.4313, Accuracy: 46.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 22/22 [00:06<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "  Train Loss: 1.0950, Accuracy: 55.67%\n",
      "  Val   Loss: 1.2414, Accuracy: 52.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 22/22 [00:07<00:00,  3.04it/s]\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\n",
      "  Train Loss: 1.1174, Accuracy: 54.95%\n",
      "  Val   Loss: 1.3372, Accuracy: 58.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 22/22 [00:06<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\n",
      "  Train Loss: 1.2250, Accuracy: 54.38%\n",
      "  Val   Loss: 1.1581, Accuracy: 58.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 22/22 [00:06<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\n",
      "  Train Loss: 1.1040, Accuracy: 55.52%\n",
      "  Val   Loss: 1.2190, Accuracy: 55.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 22/22 [00:06<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\n",
      "  Train Loss: 1.0554, Accuracy: 58.54%\n",
      "  Val   Loss: 1.1884, Accuracy: 56.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 22/22 [00:08<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\n",
      "  Train Loss: 1.0215, Accuracy: 59.83%\n",
      "  Val   Loss: 1.2132, Accuracy: 55.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 22/22 [00:06<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:\n",
      "  Train Loss: 1.0506, Accuracy: 57.96%\n",
      "  Val   Loss: 1.2322, Accuracy: 54.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 22/22 [00:06<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:\n",
      "  Train Loss: 1.0193, Accuracy: 59.83%\n",
      "  Val   Loss: 1.2252, Accuracy: 57.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 22/22 [00:06<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:\n",
      "  Train Loss: 1.0306, Accuracy: 56.67%\n",
      "  Val   Loss: 1.1162, Accuracy: 58.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 22/22 [00:06<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:\n",
      "  Train Loss: 0.9850, Accuracy: 60.83%\n",
      "  Val   Loss: 1.2159, Accuracy: 57.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 22/22 [00:06<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:\n",
      "  Train Loss: 0.9174, Accuracy: 63.56%\n",
      "  Val   Loss: 1.2239, Accuracy: 55.80%\n",
      "Modelo guardado como 'mlp_model.pth'\n",
      "Modelo guardado como 'mlp_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# Loop de entrenamiento\n",
    "n_epochs = 20\n",
    "with mlflow.start_run():\n",
    "    # Log hiperparámetros\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"MLPClassifier\",\n",
    "        \"input_size\": 64*64*3,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_fn\": \"CrossEntropyLoss\",\n",
    "        \"train_dir\": train_dir,\n",
    "        \"val_dir\": val_dir,\n",
    "    })\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "    \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        if epoch == 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                writer.add_histogram(name, param, epoch)\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "        val_loss, val_acc = evaluate(model, val_loader, epoch=epoch, prefix=\"val\")\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "        writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "        writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "    \n",
    "        # Log en MLflow\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc\n",
    "        }, step=epoch)\n",
    "        # Guardar modelo\n",
    "    torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "    print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "    mlflow.log_artifact(\"mlp_model.pth\")\n",
    "    mlflow.pytorch.log_model(model, name=\"pytorch_model\")\n",
    "    print(\"Modelo guardado como 'mlp_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "1e7a8964-f0dc-439c-b18b-b084c1afe531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6022 (pid 2900), started 0:04:49 ago. (Use '!kill 2900' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-99b727016ee54f8f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-99b727016ee54f8f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6022;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
