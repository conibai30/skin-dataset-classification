{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48aba843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2904949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "import importlib\n",
    "importlib.reload(helper)\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6ccca9e-4fec-44af-a8b7-d034101cb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import io\n",
    "from helper import *\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7eb85e50-d8ea-4a0d-82b8-dfbfa12ef379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fdb67cc-e660-4822-a999-ff80aa316a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53b1b529-ba09-4afc-a901-b04b3c07ed00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/ConstanzaBaiardi/Documents/CursoITBA/skin-dataset-classification/mlruns/2', creation_time=1766161973319, experiment_id='2', last_update_time=1766161973319, lifecycle_stage='active', name='Clasificador_Imagenes', tags={}>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3135b655-4342-4c85-9c68-46ef459de7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_classification_report(model, loader, writer, device, classes, step, prefix=\"val\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    ax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "    # Guardar localmente y subir a MLflow\n",
    "    fig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "    fig_cm.savefig(fig_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    os.remove(fig_path)\n",
    "\n",
    "    plot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=classes)\n",
    "    writer.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "    # También loguear texto del reporte\n",
    "    with open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    mlflow.log_artifact(f.name)\n",
    "    os.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64a152ed-69db-408c-9920-980b864416b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validación\n",
    "def evaluate(model, loader, writer, device, classes, epoch=None, prefix=\"val\"):\n",
    "    log_classification_report(model, loader, writer, device, classes, step=epoch , prefix=\"val\")\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Loguear imágenes del primer batch\n",
    "            if i == 0 and epoch is not None:\n",
    "                img_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "                writer.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    avg_loss = loss_sum / len(loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "        writer.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2acfa65-34ab-454c-ba1a-b2f8f1f99c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"data/Split_smol/train\"\n",
    "val_dir = \"data/Split_smol/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d86d4782-1460-4d63-b282-14ac74d1587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de logs de tensorboard\n",
    "log_dir = \"runs/experimento_skin\"\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b7b2f89-33be-4c4f-a499-8704987249ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13781267672282727"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "251b58ed-4d28-431f-a8be-2549a20402cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_space= {\n",
    "    \"model\": (\"MLPClassifier\"),\n",
    "    \"input_size\":  [32,64,128],\n",
    "    \"batch_size\": [16,64,128],\n",
    "    \"lr\": [1e-2,1e-3,1e-4],\n",
    "    \"epochs\": 200,\n",
    "    \"optimizer\":  [\"Adam\", \"SGD\"],\n",
    "    \"HFlip\": [0.0,0.5],\n",
    "    \"VFlip\": [0.0,0.5],\n",
    "    \"RBContrast\": [0.0, 0.5],\n",
    "    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "    \"train_dir\": train_dir,\n",
    "    \"val_dir\": val_dir,\n",
    "    \"es_patience\": 5,\n",
    "    \"dropout\": [0.0, 0.1,0.2,0.3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1097b11-4a9a-402e-b238-6acfe506a76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025/12/22 19:42:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025/12/22 19:43:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/22 19:43:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025/12/22 19:44:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/22 19:45:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/22 19:45:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/22 19:46:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 108\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m#print(\"Modelo guardado como 'mlp_model.pth'\")\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpytorch_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m best_epoch \u001b[38;5;241m+\u001b[39m hparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mes_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m#print(\"Early Stopping\")\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\mlflow\\pytorch\\__init__.py:288\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(pytorch_model, artifact_path, conda_env, code_paths, pickle_module, registered_model_name, signature, input_example, await_registration_for, extra_files, pip_requirements, extra_pip_requirements, metadata, name, params, tags, model_type, step, model_id, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03mLog a PyTorch model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    PyTorch logged models\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m pickle_module \u001b[38;5;241m=\u001b[39m pickle_module \u001b[38;5;129;01mor\u001b[39;00m mlflow_pytorch_pickle_module\n\u001b[1;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model\u001b[38;5;241m.\u001b[39mlog(\n\u001b[0;32m    289\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[0;32m    290\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    291\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mmlflow\u001b[38;5;241m.\u001b[39mpytorch,\n\u001b[0;32m    292\u001b[0m     pytorch_model\u001b[38;5;241m=\u001b[39mpytorch_model,\n\u001b[0;32m    293\u001b[0m     conda_env\u001b[38;5;241m=\u001b[39mconda_env,\n\u001b[0;32m    294\u001b[0m     code_paths\u001b[38;5;241m=\u001b[39mcode_paths,\n\u001b[0;32m    295\u001b[0m     pickle_module\u001b[38;5;241m=\u001b[39mpickle_module,\n\u001b[0;32m    296\u001b[0m     registered_model_name\u001b[38;5;241m=\u001b[39mregistered_model_name,\n\u001b[0;32m    297\u001b[0m     signature\u001b[38;5;241m=\u001b[39msignature,\n\u001b[0;32m    298\u001b[0m     input_example\u001b[38;5;241m=\u001b[39minput_example,\n\u001b[0;32m    299\u001b[0m     await_registration_for\u001b[38;5;241m=\u001b[39mawait_registration_for,\n\u001b[0;32m    300\u001b[0m     extra_files\u001b[38;5;241m=\u001b[39mextra_files,\n\u001b[0;32m    301\u001b[0m     pip_requirements\u001b[38;5;241m=\u001b[39mpip_requirements,\n\u001b[0;32m    302\u001b[0m     extra_pip_requirements\u001b[38;5;241m=\u001b[39mextra_pip_requirements,\n\u001b[0;32m    303\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    304\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    305\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    306\u001b[0m     model_type\u001b[38;5;241m=\u001b[39mmodel_type,\n\u001b[0;32m    307\u001b[0m     step\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m    308\u001b[0m     model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    310\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\mlflow\\models\\model.py:1210\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [pr\u001b[38;5;241m.\u001b[39muri \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pr, PromptVersion) \u001b[38;5;28;01melse\u001b[39;00m pr \u001b[38;5;28;01mfor\u001b[39;00m pr \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m   1200\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m   1201\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39martifact_location,\n\u001b[0;32m   1202\u001b[0m     model_uuid\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1208\u001b[0m     model_id\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[0;32m   1209\u001b[0m )\n\u001b[1;32m-> 1210\u001b[0m flavor\u001b[38;5;241m.\u001b[39msave_model(path\u001b[38;5;241m=\u001b[39mlocal_path, mlflow_model\u001b[38;5;241m=\u001b[39mmlflow_model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;66;03m# in __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\mlflow\\pytorch\\__init__.py:508\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(pytorch_model, path, conda_env, mlflow_model, code_paths, pickle_module, signature, input_example, extra_files, pip_requirements, extra_pip_requirements, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m     default_reqs \u001b[38;5;241m=\u001b[39m get_default_pip_requirements()\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# To ensure `_load_pyfunc` can successfully load the model during the dependency\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;66;03m# inference, `mlflow_model.save` must be called beforehand to save an MLmodel file.\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m     inferred_reqs \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_pip_requirements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mFLAVOR_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m     default_reqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(inferred_reqs)\u001b[38;5;241m.\u001b[39munion(default_reqs))\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\mlflow\\utils\\environment.py:434\u001b[0m, in \u001b[0;36minfer_pip_requirements\u001b[1;34m(model_uri, flavor, fallback, timeout, extra_env_vars)\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m _infer_requirements(\n\u001b[0;32m    431\u001b[0m                 model_uri, flavor, raise_on_error\u001b[38;5;241m=\u001b[39mraise_on_error, extra_env_vars\u001b[38;5;241m=\u001b[39mextra_env_vars\n\u001b[0;32m    432\u001b[0m             )\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_infer_requirements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_env_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_env_vars\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_error \u001b[38;5;129;01mor\u001b[39;00m (fallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py:501\u001b[0m, in \u001b[0;36m_infer_requirements\u001b[1;34m(model_uri, flavor, raise_on_error, extra_env_vars)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Infers the pip requirements of the specified model by creating a subprocess and loading\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mthe model in it to determine which packages are imported.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m \n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    499\u001b[0m _init_modules_to_packages_map()\n\u001b[1;32m--> 501\u001b[0m modules \u001b[38;5;241m=\u001b[39m \u001b[43m_capture_imported_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_env_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_env_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m packages \u001b[38;5;241m=\u001b[39m _flatten([_MODULES_TO_PACKAGES\u001b[38;5;241m.\u001b[39mget(module, []) \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules])\n\u001b[0;32m    503\u001b[0m packages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(_normalize_package_name, packages)\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py:397\u001b[0m, in \u001b[0;36m_capture_imported_modules\u001b[1;34m(model_uri, flavor, record_full_module, extra_env_vars)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _capture_modules\n\u001b[0;32m    396\u001b[0m error_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmpdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 397\u001b[0m \u001b[43m_run_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_capture_modules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--model-path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--flavor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--output-file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--error-file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--sys-path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrecord_full_module_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmain_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_MLFLOW_IN_CAPTURE_MODULE_PROCESS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_env_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(error_file):\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(error_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py:253\u001b[0m, in \u001b[0;36m_run_command\u001b[1;34m(cmd, timeout_seconds, env)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    252\u001b[0m     timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 253\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m stdout\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    255\u001b[0m     stderr \u001b[38;5;241m=\u001b[39m stderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\subprocess.py:1544\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1540\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1544\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Constanza Baiardi\\anaconda\\envs\\dl\\lib\\threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelnbr = 0\n",
    "for input_size in hparams_space[\"input_size\"]:\n",
    "    for batch_size in hparams_space[\"batch_size\"]:\n",
    "        for lr in hparams_space[\"lr\"]:\n",
    "            for optimizer in hparams_space[\"optimizer\"]:\n",
    "                for HFlip in hparams_space[\"HFlip\"]:\n",
    "                    for VFlip in hparams_space[\"VFlip\"]:\n",
    "                        for RBContrast in hparams_space[\"RBContrast\"]:\n",
    "                            for dropout in hparams_space[\"dropout\"]:\n",
    "                                if np.random.rand() < 0.05:\n",
    "                                    print(f\"modelo número: {modelnbr}\", end = \"\\r\")\n",
    "                                    modelnbr += 1\n",
    "                                    hparams= {\n",
    "                                        \"model\": (\"MLPClassifier\"),\n",
    "                                        \"input_size\":  input_size,\n",
    "                                        \"batch_size\": batch_size,\n",
    "                                        \"lr\": lr,\n",
    "                                        \"epochs\": 200,\n",
    "                                        \"optimizer\": optimizer,\n",
    "                                        \"HFlip\": HFlip,\n",
    "                                        \"VFlip\": VFlip,\n",
    "                                        \"RBContrast\": RBContrast,\n",
    "                                        \"loss_fn\": \"CrossEntropyLoss\",\n",
    "                                        \"train_dir\": train_dir,\n",
    "                                        \"val_dir\": val_dir,\n",
    "                                        \"es_patience\": 5,\n",
    "                                        \"dropout\": dropout,\n",
    "                                    }\n",
    "                                    train_transform = A.Compose([\n",
    "                                        A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                        A.HorizontalFlip(p=hparams[\"HFlip\"]),\n",
    "                                        A.VerticalFlip(p=hparams[\"VFlip\"]),\n",
    "                                        A.RandomBrightnessContrast(p=hparams[\"RBContrast\"]),\n",
    "                                        A.Normalize(),\n",
    "                                        ToTensorV2()\n",
    "                                    ])\n",
    "                                    val_test_transform = A.Compose([\n",
    "                                        A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                        A.Normalize(),\n",
    "                                        ToTensorV2()\n",
    "                                    ])\n",
    "                                    train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "                                    val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "                                    batch_size = hparams[\"batch_size\"]\n",
    "                                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                    val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "                                    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                                    num_classes = len(set(train_dataset.labels))\n",
    "                                    model = MLPClassifier(num_classes=num_classes, input_size = hparams[\"input_size\"]**2*3, dropout = hparams[\"dropout\"]).to(device)\n",
    "                                    criterion = nn.CrossEntropyLoss()\n",
    "                                    optimizer = optim.Adam(model.parameters(), lr=hparams[\"lr\"]) if hparams[\"optimizer\"]==\"Adam\" else optim.SGD(model.parameters(), lr=hparams[\"lr\"])\n",
    "                                    hparams[\"count_params\"] = count_parameters(model)\n",
    "                                    with mlflow.start_run():\n",
    "                                        # Log hiperparámetros\n",
    "                                        mlflow.log_params(hparams)\n",
    "                                        best_val_acc = 0\n",
    "                                        best_val_loss = 0\n",
    "                                        best_train_acc = 0\n",
    "                                        best_train_loss = 0\n",
    "                                        best_epoch = 0\n",
    "                                        for epoch in range(hparams[\"epochs\"]):\n",
    "                                            model.train()\n",
    "                                            running_loss = 0.0\n",
    "                                            correct, total = 0, 0\n",
    "                                        \n",
    "                                            for images, labels in train_loader:\n",
    "                                                images, labels = images.to(device), labels.to(device)\n",
    "                                        \n",
    "                                                optimizer.zero_grad()\n",
    "                                                outputs = model(images)\n",
    "                                                loss = criterion(outputs, labels)\n",
    "                                                loss.backward()\n",
    "                                                optimizer.step()\n",
    "                                        \n",
    "                                                running_loss += loss.item()\n",
    "                                                _, preds = torch.max(outputs, 1)\n",
    "                                                correct += (preds == labels).sum().item()\n",
    "                                                total += labels.size(0)\n",
    "                                        \n",
    "                                            train_loss = running_loss / len(train_loader)\n",
    "                                            train_acc = 100.0 * correct / total\n",
    "                                            val_loss, val_acc = evaluate(model, val_loader, writer, device,train_dataset.label_encoder.classes_,epoch=epoch, prefix=\"val\")\n",
    "                                        \n",
    "                                            #print(f\"Epoch {epoch+1}:\")\n",
    "                                            #print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "                                            #print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "                                        \n",
    "                                            writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "                                            writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "                                        \n",
    "                                            # Log en MLflow\n",
    "                                            mlflow.log_metrics({\n",
    "                                                \"train_loss\": train_loss,\n",
    "                                                \"train_accuracy\": train_acc,\n",
    "                                                \"val_loss\": val_loss,\n",
    "                                                \"val_accuracy\": val_acc\n",
    "                                            }, step=epoch)\n",
    "                                            if val_acc > best_val_acc:\n",
    "                                                best_val_acc = val_acc\n",
    "                                                best_val_loss = val_loss\n",
    "                                                best_train_acc = train_acc\n",
    "                                                best_train_loss = train_loss\n",
    "                                                best_epoch = epoch\n",
    "                                                # Guardar modelo\n",
    "                                                torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "                                                #print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "                                                mlflow.log_artifact(\"mlp_model.pth\")\n",
    "                                                mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "                                            elif epoch > best_epoch + hparams[\"es_patience\"]:\n",
    "                                                #print(\"Early Stopping\")\n",
    "                                                break\n",
    "                                                \n",
    "                                        mlflow.log_metrics({\n",
    "                                                \"train_loss\": best_train_loss,\n",
    "                                                \"train_accuracy\": best_train_acc,\n",
    "                                                \"val_loss\": best_val_loss,\n",
    "                                                \"val_accuracy\": best_val_acc,\n",
    "                                                \"best_epoch\": best_epoch\n",
    "                                            }, step=epoch+1)                                                \n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585580ed-3db0-4687-8ab5-a09abacc621b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594da669-b48e-4307-bd29-11cd988fb4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34241d72-902a-491a-a1e5-a6ec756ab54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
